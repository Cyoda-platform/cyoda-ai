{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Cyoda configurations Q&A with RAG Langchain\n",
    "\n",
    "This is a playground for experimenting with connections generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "WORK_DIR = os.environ[\"WORK_DIR\"]\n",
    "API_KEY = os.environ[\"CYODA_API_KEY\"]\n",
    "API_SECRET = os.environ[\"CYODA_API_SECRET\"]\n",
    "API_URL = os.environ[\"CYODA_API_URL\"]+\"/api\"\n",
    "GRPC_ADDRESS = os.environ[\"GRPC_ADDRESS\"]\n",
    "WORK_DIR = os.environ[\"WORK_DIR\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "WORK_DIR = os.environ[\"WORK_DIR\"]\n",
    "TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "##for google colab (optional)\n",
    "# This cell is optional and can be skipped\n",
    "from google.colab import userdata\n",
    "API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "WORK_DIR = userdata.get('WORK_DIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle unsupported version of sqlite3 (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pysqlite3-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "__import__(\"pysqlite3\")\n",
    "sys.modules[\"sqlite3\"] = sys.modules[\"pysqlite3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import GitLoader, DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.45,\n",
    "    max_tokens=4000,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load instructions and entities from the official cyoda repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "loader = GitLoader(\n",
    "    repo_path=WORK_DIR,\n",
    "    branch=\"cyoda-ai-configurations-3.0.x\",\n",
    "    file_filter=lambda file_path: file_path.startswith(f\"{WORK_DIR}/data/rag/v1/connections/templates\"),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\n",
    "    f\"{WORK_DIR}/data/rag/v1/connections\", loader_cls=TextLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents loaded: {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents and create vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(\n",
    "            documents=splits, embedding=OpenAIEmbeddings()\n",
    "        )\n",
    "retriever = vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 10}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = vectorstore._collection.count()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define prompts for contextualizing question and answering question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are a connection generation assistant. \\\n",
    "You will be asked to generate connection configurations. \\\n",
    "First, analyse the human message and choose a template to fill in: [Connections Questionnaire, HttpConnectionDetailsDto, HttpEndpointDto] \\\n",
    "Then fill in the values inside $ with curly brackets in the template. Other values in the template should be preserved. Treat it like a test where you need to fill in the blanks. But you cannot modify values out of the scope of your test. \\\n",
    "Construct and return only the json for the bean you are asked for. Return the resulting json without any comments.  \n",
    "{context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize chat history and relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a message to the chat history\n",
    "def add_to_chat_history(id, question, message):\n",
    "    if id in chat_history:\n",
    "        chat_history[id].extend([HumanMessage(content=question), message])\n",
    "    else:\n",
    "        chat_history[id] = [HumanMessage(content=question), message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear chat history\n",
    "def clear_chat_history(id):\n",
    "    if id in chat_history:\n",
    "        del chat_history[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(id, question):\n",
    "    ai_msg = rag_chain.invoke(\n",
    "        {\"input\": question, \"chat_history\": chat_history.get(id, [])}\n",
    "    )\n",
    "    add_to_chat_history(id, question, ai_msg[\"answer\"])\n",
    "    return ai_msg[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique ID for the chat session\n",
    "id = uuid.uuid1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear chat history if necessary\n",
    "clear_chat_history(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(result):\n",
    "    if result.startswith(\"```\"):\n",
    "        return \"\\n\".join(result.split(\"\\n\")[1:-1])\n",
    "    if not result.startswith(\"{\"):\n",
    "        start_index = result.find(\"```json\")\n",
    "        if start_index != -1:\n",
    "            start_index += len(\"```json\\n\")\n",
    "            end_index = result.find(\"```\", start_index)\n",
    "            return result[start_index:end_index].strip()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uuid() -> uuid:\n",
    "    return uuid.uuid1()\n",
    "\n",
    "generate_uuid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Optional \n",
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def generate_uuid_tool(meta: Optional[str]) -> uuid:\n",
    "    \"\"\"Returns random uuid.\"\"\"\n",
    "    return generate_uuid()\n",
    "\n",
    "\n",
    "generate_uuid_tool.invoke(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Optional \n",
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_web_page_by_url(url: Optional[str]) -> uuid:\n",
    "    \"\"\"Returns random uuid.\"\"\"\n",
    "    return generate_uuid()\n",
    "\n",
    "\n",
    "generate_uuid_tool.invoke(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def generate_connection(config: str) -> str:\n",
    "    \"\"\"Generates a com.cyoda.plugins.datasource.dtos.connection.HttpConnectionDetailsDto connection for the given data source API configuration\"\"\"\n",
    "    question = f\"Create a com.cyoda.plugins.datasource.dtos.connection.HttpConnectionDetailsDto connection for data source: {config}\"\n",
    "    result = ask_question(id, question)\n",
    "    print(result)\n",
    "    parsed_result = parse_json(result)\n",
    "    print(parsed_result)\n",
    "    return parsed_result\n",
    "\n",
    "\n",
    "#generate_connection.invoke(\"ARTISTS_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def generate_endpoint(config: str, endpoint: str) -> str:\n",
    "    \"\"\"Generates a com.cyoda.plugins.datasource.dtos.endpoint.HttpEndpointDto endpoint config for the given data source API configuration\"\"\"\n",
    "    question = f\"Create a com.cyoda.plugins.datasource.dtos.endpoint.HttpEndpointDto endpoint for data source: {config} endpoint {endpoint}\"\n",
    "    result = ask_question(id, question)\n",
    "    parsed_result = parse_json(result)\n",
    "    return parsed_result\n",
    "\n",
    "\n",
    "#generate_endpoint.invoke(\"ARTISTS_API\", \"get_by_username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonschema\n",
    "from jsonschema import validate\n",
    "\n",
    "\n",
    "def validate_result(parsed_result: str, file_path: str) -> bool:\n",
    "    with open(file_path, 'r') as schema_file:\n",
    "        schema = json.load(schema_file)\n",
    "\n",
    "    json_data = json.loads(parsed_result)\n",
    "\n",
    "    try:\n",
    "        validate(instance=json_data, schema=schema)\n",
    "        print(\"JSON is valid.\")\n",
    "        return True\n",
    "    except jsonschema.exceptions.ValidationError as err:\n",
    "        print(\"JSON is invalid:\", err.message)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def validate_result_connection(connection_dto_config: str) -> str:\n",
    "    \"\"\"Validates the resulting com.cyoda.plugins.datasource.dtos.connection.HttpConnectionDetailsDto config\"\"\"\n",
    "    result = validate_result(connection_dto_config, f'{WORK_DIR}/data/v1/connections/connection_json_schema.json')\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def validate_result_endpoint(endpoint_dto_config: str) -> str:\n",
    "    \"\"\"Validates the resulting com.cyoda.plugins.datasource.dtos.endpoint.HttpEndpointDto config\"\"\"\n",
    "    result = validate_result(endpoint_dto_config, f'{WORK_DIR}/data/v1/connections/endpoint_json_schema.json')\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [generate_uuid, generate_connection, validate_result_connection, generate_endpoint, validate_result_endpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"Fill in Connections Questionnaire json based on the user question: \\\"Generate connection for ARTISTS_API\\\". Return only Questionnnaire json.\"\n",
    "questionnaire_result = ask_question(id, question)\n",
    "print(questionnaire_result)\n",
    "try:\n",
    "    parsed_questionnaire_result = parse_json(questionnaire_result)\n",
    "    print(parsed_questionnaire_result)\n",
    "    parsed_questionnaire_result_json = json.loads(parsed_questionnaire_result)  \n",
    "except Exception as e:\n",
    "    print(\"error\")\n",
    "    print(parsed_questionnaire_result)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed_questionnaire_result_json['connection_name'])\n",
    "connection_name = parsed_questionnaire_result_json['connection_name']\n",
    "connection_type = parsed_questionnaire_result_json['connection_type']\n",
    "connection_base_url = parsed_questionnaire_result_json['connection_base_url']\n",
    "connection_endpoints = parsed_questionnaire_result_json['connection_endpoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"Write com.cyoda.plugins.datasource.dtos.connection.HttpConnectionDetailsDto connection config for api {connection_name} with base_url {connection_base_url}. Return only com.cyoda.plugins.datasource.dtos.connection.HttpConnectionDetailsDto json.\"\n",
    "connection_result = ask_question(id, question)\n",
    "print(connection_result)\n",
    "try:\n",
    "    parsed_connection_result = parse_json(connection_result)\n",
    "    print(parsed_connection_result)\n",
    "    result = validate_result(parsed_connection_result, f'{WORK_DIR}/data/v1/connections/connection_json_schema.json')\n",
    "    if not result:\n",
    "        print(\"error\")\n",
    "        print(parsed_connection_result)           \n",
    "except Exception as e:\n",
    "    print(\"error\")\n",
    "    print(parsed_connection_result)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(parsed_connection_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints_list = connection_endpoints\n",
    "print(type(endpoints_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_configs = []\n",
    "for endpoint_name in endpoints_list:\n",
    "    print(endpoint_name)\n",
    "    question = f\"Now generate com.cyoda.plugins.datasource.dtos.endpoint.HttpEndpointDto endpoint config for {endpoint_name}. Only one endpoint. Return only com.cyoda.plugins.datasource.dtos.endpoint.HttpEndpointDto json.\"\n",
    "    endpoint_result = ask_question(id, question)\n",
    "    print(endpoint_result)\n",
    "    try:\n",
    "        parsed_endpoint_result = parse_json(endpoint_result)\n",
    "        print(parsed_endpoint_result)\n",
    "        result = validate_result(parsed_endpoint_result, f'{WORK_DIR}/data/v1/connections/endpoint_json_schema.json')\n",
    "        if result:\n",
    "            endpoint_configs.append(parsed_endpoint_result)\n",
    "        else:\n",
    "            print(\"error\")\n",
    "            print(parsed_endpoint_result)           \n",
    "    except Exception as e:\n",
    "        print(\"error\")\n",
    "        print(parsed_endpoint_result)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(endpoint_configs)\n",
    "print(type(endpoint_configs[0]))\n",
    "print(len(endpoint_configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_result_connection(connection_template_file_path: str, name: str, connection, endpoints):\n",
    "    data = ''\n",
    "    try:\n",
    "        with open(connection_template_file_path, 'r') as file:\n",
    "            data = file.read()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read JSON file: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        data = json.loads(data)  # Parse the JSON string into a dictionary\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Failed to decode JSON: {e}\")\n",
    "        return\n",
    "    try:\n",
    "        data['dataSources'][0]['name']=name\n",
    "        data['dataSources'][0]['id']=str(generate_uuid())\n",
    "        data['dataSources'][0]['connections'].append(connection)\n",
    "        data['dataSources'][0]['endpoints'].extend(endpoints)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Failed to decode result as JSON: {e}\")\n",
    "        return\n",
    "\n",
    "    # Convert the modified dictionary back to a JSON string\n",
    "    data = json.dumps(data, indent=4)\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_connection_result_json = json.loads(parsed_connection_result)\n",
    "endpoint_configs_str = json.dumps(endpoint_configs, indent=4)\n",
    "endpoint_configs_json = [json.loads(item) for item in endpoint_configs]\n",
    "print(type(parsed_connection_result_json))\n",
    "print(type(endpoint_configs_json))\n",
    "result = build_result_connection(f'{WORK_DIR}/data/v1/connections/connection_dto_template.json', \n",
    "                                 'ARTISTS_API',\n",
    "                                 parsed_connection_result_json,\n",
    "                                 endpoint_configs_json )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear chat history if necessary\n",
    "clear_chat_history(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "api_url = API_URL + \"/auth/login\"\n",
    "headers = {\"Content-Type\": \"application/json\", \"X-Requested-With\": \"XMLHttpRequest\"}\n",
    "auth_data = {\"username\": API_KEY, \"password\": API_SECRET}\n",
    "response = requests.post(api_url, headers=headers, data=json.dumps(auth_data))\n",
    "if response.status_code == 200:\n",
    "    logger.info(\"Authentication successful!\")\n",
    "    TOKEN = response.json().get(\"token\")\n",
    "else:\n",
    "    logger.info(\"Authentication failed. Please check your API credentials.\")\n",
    "    \n",
    "def send_post_request(\n",
    "    token: str, api_url: str, path: str, data, json\n",
    ") -> Optional[requests.Response]:\n",
    "    url = f\"{api_url}/{path}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=data, json=json)\n",
    "        return response\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err}\")\n",
    "    except Exception as err:\n",
    "        logger.error(f\"Other error occurred: {err}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data):\n",
    "    path = f\"data-source-config/import-cobi-config?cleanBeforeImport=false&doPostProcess=false\"\n",
    "    response = send_post_request(token=TOKEN, api_url=API_URL, path=path, data=data, json=None)\n",
    "    logger.info(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)\n",
    "print(type(result))\n",
    "save_data(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

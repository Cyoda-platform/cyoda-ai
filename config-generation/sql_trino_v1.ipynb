{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Cyoda configurations Q&A with RAG Langchain\n",
    "\n",
    "This is a playground for experimenting with trino queries generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import base64\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "WORK_DIR = os.environ[\"WORK_DIR\"]\n",
    "decoded_bytes_user = base64.b64decode(os.environ[\"TRINO_USER\"])\n",
    "TRINO_USER = decoded_bytes_user.decode(\"utf-8\")\n",
    "decoded_bytes_pwd = base64.b64decode(os.environ[\"TRINO_PASSWORD\"])\n",
    "TRINO_PASSWORD = decoded_bytes_pwd.decode(\"utf-8\")\n",
    "TRINO_CONNECTION_PATH=os.environ[\"TRINO_CONNECTION_PATH\"]\n",
    "TRINO_CONNECTION_STRING = f\"trino://{TRINO_USER}:{TRINO_PASSWORD}@{TRINO_CONNECTION_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "##for google colab (optional)\n",
    "# This cell is optional and can be skipped\n",
    "from google.colab import userdata\n",
    "API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "WORK_DIR = userdata.get('WORK_DIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle unsupported version of sqlite3 (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pysqlite3-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "__import__(\"pysqlite3\")\n",
    "sys.modules[\"sqlite3\"] = sys.modules[\"pysqlite3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import GitLoader, DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    max_tokens=8000,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load instructions and entities from the official cyoda repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "loader = GitLoader(\n",
    "    repo_path=WORK_DIR,\n",
    "    branch=\"cyoda-ai-configurations-3.0.x\",\n",
    "    file_filter=lambda file_path: file_path.startswith(f\"{WORK_DIR}/data/code/\"),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\n",
    "    f\"{WORK_DIR}/data/rag/v1/trino\", loader_cls=TextLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents and create vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(\n",
    "            documents=splits, embedding=OpenAIEmbeddings()\n",
    "        )\n",
    "retriever = vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 10}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = vectorstore._collection.count()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define prompts for contextualizing question and answering question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are a Trino expert. Given an input question, \n",
    "first create a syntactically correct Trino sql query to run, \n",
    "then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, \n",
    "query for at most 100 results using the LIMIT clause as per sql.\n",
    "You can order the results to return the most informative data in the database.\n",
    "You must query only the columns that are needed to answer the question. \n",
    "Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use date('now') function to get the current date, if the question involves \"today\\\n",
    "You can do joins only on indexes!\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize chat history and relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a message to the chat history\n",
    "def add_to_chat_history(id, question, message):\n",
    "    if id in chat_history:\n",
    "        chat_history[id].extend([HumanMessage(content=question), message])\n",
    "    else:\n",
    "        chat_history[id] = [HumanMessage(content=question), message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear chat history\n",
    "def clear_chat_history(id):\n",
    "    if id in chat_history:\n",
    "        del chat_history[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(id, question):\n",
    "    ai_msg = rag_chain.invoke(\n",
    "        {\"input\": question, \"chat_history\": chat_history.get(id, [])}\n",
    "    )\n",
    "    add_to_chat_history(id, question, ai_msg[\"answer\"])\n",
    "    return ai_msg[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique ID for the chat session\n",
    "id = uuid.uuid1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear chat history if necessary\n",
    "clear_chat_history(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install trino==0.329.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f\"trino://{TRINO_USER}:{TRINO_PASSWORD}@{TRINO_CONNECTION_PATH}/information_schema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Optional \n",
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def run_sql_query(sql_query: str) -> str:\n",
    "    \"\"\"Runs sql query and returns the dataset from the database.\"\"\"\n",
    "    try:\n",
    "        result = db.run(sql_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return str(e.__cause__)\n",
    "\n",
    "run_sql_query.invoke(\"SELECT schema_data_ds_id FROM sch1.ingest_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT institution, COUNT(*) AS number_of_laureates \\\n",
    "FROM prizes.prizes_data_prizes_laureates \\\n",
    "GROUP BY institution \\\n",
    "ORDER BY number_of_laureates DESC\"\n",
    "\n",
    "schema_query = \"SELECT institution, COUNT(*) AS number_of_laureates \\\n",
    "FROM prizes.prizes_data_prizes_laureates \\\n",
    "GROUP BY institution \\\n",
    "ORDER BY number_of_laureates DESC\"\n",
    "try:\n",
    "    result = run_sql_query.invoke(query)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(e.__cause__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def generate_trino_sql(question: str, chat_id: str) -> str:\n",
    "    \"\"\"Generates sql query based on user question\"\"\"\n",
    "    try:\n",
    "        question = f\"{question}. Remove any ; (semi colon) at the end\"\n",
    "        ai_msg = rag_chain.invoke(\n",
    "            {\"input\": question, \"chat_history\": chat_history.get(chat_id, [])}\n",
    "        )\n",
    "        add_to_chat_history(id, question, ai_msg[\"answer\"])\n",
    "        return ai_msg[\"answer\"]\n",
    "    except Exception as e:\n",
    "        return str(e.__cause__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [run_sql_query, generate_trino_sql]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Make sure to use the generate_trino_sql tool to formulate the query. As it is trino and cyoda specific. Make sure the is no semi-colon at the end of the query. Retry up to 1 time if necessary.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Construct the Tools agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, vectorstore=vectorstore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor.invoke({\"input\": \"What tables do you have in schema prizes? Analyse tables structure.  PLease use chat_id \\\"123\\\"\"})\n",
    "ask_question(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['output'])\n",
    "ask_question(\"123\", f\"Remeber the results of sql execution: {result['output']}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT institution, COUNT(*) AS number_of_laureates \\\n",
    "FROM prizes.prizes_data_prizes_laureates \\\n",
    "GROUP BY institution \\\n",
    "ORDER BY number_of_laureates DESC;\"\n",
    "result = agent_executor.invoke({\"input\": f\"Execute {query}. If you get error, fix the query, explain how you fixesd it and retry after correcting the query. Max retries = 3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many laureates were in 2020. Please use chat_id = 123\"\n",
    "result = agent_executor.invoke({\"input\": f\"Execute {query}. If you get error, fix the query, explain how you fixesd it and retry after correcting the query. Max retries = 3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question(\"123\", f\"Remeber the results of sql execution: {result['output']}\" )\n",
    "print(result['output'])\n",
    "ask_question(\"123\", \"How many laureates were in 2020. Please use chat_id = 123\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT firstname, surname, COUNT(DISTINCT category) AS number_of_categories \\\n",
    "FROM prizes.prizes_data_prizes_laureates \\\n",
    "GROUP BY firstname, surname \\\n",
    "HAVING COUNT(DISTINCT category) > 1\"\n",
    "result = agent_executor.invoke({\"input\": f\"Execute {query}. If you get error, fix the query, explain how you fixesd it and retry after correcting the query. Max retries = 3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

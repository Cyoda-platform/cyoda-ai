{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Cyoda configurations Q&A with RAG Langchain\n",
    "\n",
    "This is a playground for experimenting with workflow generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "WORK_DIR = os.environ[\"WORK_DIR\"]\n",
    "API_URL = os.environ[\"CYODA_API_URL\"]+\"/api\"\n",
    "API_KEY = os.environ[\"CYODA_API_KEY\"]\n",
    "API_SECRET = os.environ[\"CYODA_API_SECRET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "##for google colab (optional)\n",
    "# This cell is optional and can be skipped\n",
    "from google.colab import userdata\n",
    "API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "WORK_DIR = userdata.get('WORK_DIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle unsupported version of sqlite3 (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pysqlite3-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "__import__(\"pysqlite3\")\n",
    "sys.modules[\"sqlite3\"] = sys.modules[\"pysqlite3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import GitLoader, DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    max_tokens=16000,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(WORK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\n",
    "    f\"{WORK_DIR}/data/rag/v1/workflows\", loader_cls=TextLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "loader = GitLoader(repo_path=\"/tmp/cyoda-ai-chat\",\n",
    "                   clone_url=\"https://github.com/Cyoda-platform/cyoda-ai-chat\",\n",
    "                   branch=\"develop\")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents and create vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(\n",
    "            documents=splits, embedding=OpenAIEmbeddings()\n",
    "        )\n",
    "retriever = vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 10}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = vectorstore._collection.count()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define prompts for contextualizing question and answering question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_string(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"{prompt} /\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize chat history and relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a message to the chat history\n",
    "def add_to_chat_history(id, question, message):\n",
    "    if id in chat_history:\n",
    "        chat_history[id].extend([HumanMessage(content=question), message])\n",
    "    else:\n",
    "        chat_history[id] = [HumanMessage(content=question), message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear chat history\n",
    "def clear_chat_history(id):\n",
    "    if id in chat_history:\n",
    "        del chat_history[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = read_file_to_string(f\"{WORK_DIR}/data/v1/workflows/prompt.txt\")\n",
    "def ask_question(id, question):\n",
    "    ai_msg = rag_chain.invoke(\n",
    "        {\"input\": question, \"chat_history\": chat_history.get(id, []), \"prompt\": prompt }\n",
    "    )\n",
    "    add_to_chat_history(id, question, ai_msg[\"answer\"])\n",
    "    return ai_msg[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique ID for the chat session\n",
    "id = uuid.uuid1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rewrite CyodaCalculationMemberClient to java. Produce ready to use code. Leave spring boot\n",
    "question = \"hello, how r u\"\n",
    "result = ask_question(id, question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear chat history if necessary\n",
    "clear_chat_history(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "api_url = API_URL + \"/auth/login\"\n",
    "headers = {\"Content-Type\": \"application/json\", \"X-Requested-With\": \"XMLHttpRequest\"}\n",
    "auth_data = {\"username\": API_KEY, \"password\": API_SECRET}\n",
    "logger.info(api_url)\n",
    "response = requests.post(api_url, headers=headers, data=json.dumps(auth_data))\n",
    "if response.status_code == 200:\n",
    "    logger.info(\"Authentication successful!\")\n",
    "    TOKEN = response.json().get(\"token\")\n",
    "else:\n",
    "    logger.info(\"Authentication failed. Please check your API credentials.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_post_request(path, data):\n",
    "    url = f\"{API_URL}/{path}\"\n",
    "    print(url)\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_get_request(path):\n",
    "    url = f\"{API_URL}/{path}\"\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    \"\"\"Read and return JSON data from a file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read JSON file {file_path}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"Read and return JSON data from a file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read JSON file {file_path}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workflow(file_path):\n",
    "    \"\"\"Get workflow data from a file and POST it.\"\"\"\n",
    "    workflow_view = read_file(file_path)\n",
    "    path = \"platform-api/statemachine/persisted/workflows\"\n",
    "    response = send_post_request(path, workflow_view)\n",
    "    if response.status_code // 100 != 2:\n",
    "        logger.error(f\"POST request failed with status code {response.status_code}\")\n",
    "        response.raise_for_status()\n",
    "    return response.json()['id']\n",
    "\n",
    "def get_empty_transition(workflow_id, file_path):\n",
    "    \"\"\"Get empty transition id from a file and POST it.\"\"\"\n",
    "    data = read_json_file(file_path)\n",
    "    data['workflowId']=workflow_id\n",
    "    data = json.dumps(data)\n",
    "    path = f\"platform-api/statemachine/persisted/workflows/{workflow_id}/transitions\"\n",
    "    response = send_post_request(path, data)\n",
    "    if response.status_code // 100 != 2:\n",
    "        print(response.json())\n",
    "        logger.error(f\"POST request failed with status code {response.status_code}\")\n",
    "        response.raise_for_status()\n",
    "    return response.json()['Data']['id']\n",
    "\n",
    "def get_existing_states(workflow_id):\n",
    "    \"\"\"Retrieve existing states for the given workflow ID.\"\"\"\n",
    "    path = f\"platform-api/statemachine/persisted/workflows/{workflow_id}/states\"\n",
    "    res = send_get_request(path)\n",
    "    if res.status_code // 100 != 2:\n",
    "        logger.error(f\"GET request failed with status code {res.status_code}\")\n",
    "        res.raise_for_status()\n",
    "    return res.json()\n",
    "\n",
    "def create_state_mapping(workflow_states):\n",
    "    \"\"\"Create mappings for state descriptions and IDs.\"\"\"\n",
    "    state_dscr_map = {item['name']: item['description'] for item in workflow_states['Data']}\n",
    "    state_id_map = {item['name']: item['id'] for item in workflow_states['Data']}\n",
    "    state_id_map['None'] = \"noneState\"\n",
    "    return state_dscr_map, state_id_map\n",
    "\n",
    "def update_states(workflow_id, file_path, existing_state_id_map):\n",
    "    \"\"\"Update states based on a JSON file and the existing state ID map.\"\"\"\n",
    "    data = read_json_file(file_path)\n",
    "    states = {item['end_state']: item['end_state_description'] for item in data['transitions']}\n",
    "    empty_transition_id = get_empty_transition(workflow_id, f\"{WORK_DIR}/data/v1/workflows/initial_transition.json\")\n",
    "    path = f\"platform-api/statemachine/persisted/workflows/{workflow_id}/transitions/{empty_transition_id}/states\"\n",
    "    state_template = read_json_file(f\"{WORK_DIR}/data/v1/workflows/state.json\")\n",
    "    \n",
    "    for name, dscr in states.items():\n",
    "        if name not in existing_state_id_map:\n",
    "            state_template[\"name\"] = name\n",
    "            state_template[\"description\"] = dscr\n",
    "            response = send_post_request(path, json.dumps(state_template))\n",
    "            if response.status_code // 100 != 2:\n",
    "                logger.error(f\"POST request failed with status code {response.status_code}\")\n",
    "                response.raise_for_status()\n",
    "            id = response.json()[\"Data\"][\"id\"]\n",
    "            existing_state_id_map[name] = id\n",
    "\n",
    "def update_transitions(file_path, existing_state_id_map, workflow_id):\n",
    "    \"\"\"Update transitions based on a JSON file and the existing state ID map.\"\"\"\n",
    "    data = read_json_file(file_path)\n",
    "    transition_template = read_json_file(f\"{WORK_DIR}/data/v1/workflows/transition.json\")\n",
    "    \n",
    "    save_transition_path = f\"platform-api/statemachine/persisted/workflows/{workflow_id}/transitions\"\n",
    "    \n",
    "    for item in data['transitions']:\n",
    "        transition_template.update({\n",
    "            'name': item['name'],\n",
    "            'description': item['description'],\n",
    "            'startStateId': existing_state_id_map[item['start_state']],\n",
    "            'endStateId': existing_state_id_map[item['end_state']],\n",
    "            'workflowId': workflow_id\n",
    "        })\n",
    "        response = send_post_request(save_transition_path, json.dumps(transition_template))\n",
    "        if response.status_code // 100 != 2:\n",
    "            logger.error(f\"POST request failed with status code {response.status_code}\")\n",
    "            response.raise_for_status()\n",
    "        print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_file_path = f\"{WORK_DIR}/data/v1/workflows/workflow.json\"\n",
    "workflow_id = get_workflow(workflow_file_path)\n",
    "\n",
    "workflow_states = get_existing_states(workflow_id)\n",
    "existing_state_dscr_map, existing_state_id_map = create_state_mapping(workflow_states)\n",
    "\n",
    "state_file_path = f\"{WORK_DIR}/data/test-inputs/v1/workflows/test_res.json\"\n",
    "update_states(workflow_id, state_file_path, existing_state_id_map)\n",
    "\n",
    "transition_file_path = f\"{WORK_DIR}/data/test-inputs/v1/workflows/test_res.json\"\n",
    "update_transitions(transition_file_path, existing_state_id_map, workflow_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##provide image url\n",
    "image_url = \"\"\n",
    "\n",
    "import base64\n",
    "import httpx\n",
    "image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = read_file_to_string(f\"{WORK_DIR}/data/v1/workflows/prompt.txt\")\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": f\"Generate the workflow from the image. Base on the system prompt: {prompt}\"},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "response = llm.invoke([message])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(rag_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(result):\n",
    "    if result.startswith(\"```\"):\n",
    "        return \"\\n\".join(result.split(\"\\n\")[1:-1])\n",
    "    if not result.startswith(\"{\"):\n",
    "        start_index = result.find(\"```json\")\n",
    "        if start_index != -1:\n",
    "            start_index += len(\"```json\\n\")\n",
    "            end_index = result.find(\"```\", start_index)\n",
    "            return result[start_index:end_index].strip()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = parse_json(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_chat_history(id, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rewrite CyodaCalculationMemberClient to java. Produce ready to use code. Leave spring boot\n",
    "question = \"how many transitions in the workflow\"\n",
    "result = ask_question(id, question)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

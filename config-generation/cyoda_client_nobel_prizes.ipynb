{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f2c870",
   "metadata": {},
   "source": [
    "\n",
    "Cyoda Client Demo\n",
    "\n",
    "Welcome to the Cyoda Client Demo! This notebook demonstrates how to connect and interact with the Cyoda API. Follow the steps below to get started.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running the cells, ensure you have the following:\n",
    "- Cyoda API credentials (API key, secret, etc.)\n",
    "- Necessary Python packages installed\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. **Setup**: Import required libraries and set up the environment.\n",
    "2. **Authentication**: Authenticate with the Cyoda API.\n",
    "3. **Basic Operations**: Perform basic operations using the API.\n",
    "4. **Advanced Features**: Explore advanced features and functionalities.\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment variables\n",
    "import os\n",
    "\n",
    "API_KEY = os.environ[\"CYODA_API_KEY\"]\n",
    "API_SECRET = os.environ[\"CYODA_API_SECRET\"]\n",
    "API_URL = os.environ[\"CYODA_API_URL\"]+\"/api\"\n",
    "GRPC_ADDRESS = os.environ[\"GRPC_ADDRESS\"]\n",
    "WORK_DIR = os.environ[\"WORK_DIR\"]\n",
    "TOKEN = \"\"\n",
    "print(API_URL)\n",
    "print(GRPC_ADDRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_CLASS_NAME = \"com.cyoda.tdb.model.treenode.TreeNodeEntity\"\n",
    "ENTITY_NAME=\"prizes\"\n",
    "AGG_ENTITY_NAME=ENTITY_NAME+\"_agg\"\n",
    "MODEL_VERSION=\"1001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f64a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with the Cyoda API\n",
    "import requests\n",
    "import json\n",
    "\n",
    "api_url = API_URL + \"/auth/login\"\n",
    "headers = {\"Content-Type\": \"application/json\", \"X-Requested-With\": \"XMLHttpRequest\"}\n",
    "auth_data = {\"username\": API_KEY, \"password\": API_SECRET}\n",
    "logger.info(api_url)\n",
    "response = requests.post(api_url, headers=headers, data=json.dumps(auth_data))\n",
    "if response.status_code == 200:\n",
    "    logger.info(\"Authentication successful!\")\n",
    "    TOKEN = response.json().get(\"token\")\n",
    "else:\n",
    "    logger.info(\"Authentication failed. Please check your API credentials.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_get_request(path):\n",
    "    url = f\"{API_URL}/{path}\"\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_post_request(path, data):\n",
    "    url = f\"{API_URL}/{path}\"\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_put_request(path, data, timeout):\n",
    "    url = f\"{API_URL}/{path}\"\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "    response = requests.put(url, headers=headers, data=data, timeout=timeout)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_delete_request(path):\n",
    "    url = f\"{API_URL}/{path}\"\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "    response = requests.delete(url, headers=headers)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_entity_data(entity_name, version):\n",
    "    path = f\"entity/TREE/{entity_name}/{version}\"\n",
    "    response = send_delete_request(path=path)\n",
    "    logger.info(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = delete_entity_data(ENTITY_NAME, MODEL_VERSION)\n",
    "logger.info(response)\n",
    "\n",
    "response = delete_entity_data(AGG_ENTITY_NAME, MODEL_VERSION)\n",
    "logger.info(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_entity_schema(entity_name, version):\n",
    "    path = f\"treeNode/model/{entity_name}/{version}\"\n",
    "    response = send_delete_request(path=path)\n",
    "    logger.info(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = delete_entity_schema(ENTITY_NAME, MODEL_VERSION)\n",
    "logger.info(response)\n",
    "\n",
    "response = delete_entity_schema(AGG_ENTITY_NAME, MODEL_VERSION)\n",
    "logger.info(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_entity_schema(entity_name, version, data):\n",
    "    path = f\"treeNode/model/import/JSON/SAMPLE_DATA/{entity_name}/{version}\"\n",
    "    response = send_post_request(path=path, data=data)\n",
    "    logger.info(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_post_request_with_file(path, file_path):\n",
    "    url = f\"{API_URL}/{path}\"\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "    files = {'file': open(file_path, 'rb')}\n",
    "    \n",
    "    response = requests.post(url, headers=headers, files=files)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "path = f\"treeNode/model/import/file/JSON/SAMPLE_DATA/{ENTITY_NAME}/{MODEL_VERSION}\"\n",
    "file_path = f\"{WORK_DIR}/config-generation/prizes_schema.json\"\n",
    "\n",
    "response = send_post_request_with_file(path, file_path)\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_post_request_with_file(path, file_path):\n",
    "    url = f\"{API_URL}/{path}\"\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "    files = {'file': open(file_path, 'rb')}\n",
    "    \n",
    "    response = requests.post(url, headers=headers, files=files)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "path = f\"entity/new/file/JSON/TREE/{ENTITY_NAME}/{MODEL_VERSION}\"\n",
    "file_path = f\"{WORK_DIR}/config-generation/prizes_entities.json\"\n",
    "\n",
    "response = send_post_request_with_file(path, file_path)\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_save_schema(entity_name, data):\n",
    "    response = save_entity_schema(\n",
    "        entity_name=entity_name, version=MODEL_VERSION, data=data\n",
    "    )\n",
    "    logger.info(response)\n",
    "    assert (\n",
    "        response.status_code == 200\n",
    "    ), f\"Expected 200, got {response.status_code}\"\n",
    "data = \"{\\\"extraction-date\\\": \\\"2024-04-14\\\", \\\"data\\\": {\\\"source\\\": \\\"taken from http://api.nobelprize.org/v1/prize.json\\\", \\\"prizes\\\": [{\\\"year\\\": \\\"2020\\\", \\\"category\\\": \\\"chemistry\\\", \\\"laureates\\\": [{\\\"id\\\": \\\"991\\\", \\\"firstname\\\": \\\"Emmanuelle\\\", \\\"surname\\\": \\\"Charpentier\\\", \\\"motivation\\\": \\\"\\\\\\\"for the development of a method for genome editing\\\\\\\"\\\", \\\"share\\\": \\\"2\\\"}, {\\\"id\\\": \\\"992\\\", \\\"firstname\\\": \\\"Jennifer A.\\\", \\\"surname\\\": \\\"Doudna\\\", \\\"motivation\\\": \\\"\\\\\\\"for the development of a method for genome editing\\\\\\\"\\\", \\\"share\\\": \\\"2\\\"}], \\\"summary\\\": \\\"test\\\"}, {\\\"year\\\": \\\"2019\\\", \\\"category\\\": \\\"physics\\\", \\\"overallMotivation\\\": \\\"\\\\\\\"for contributions to our understanding of the evolution of the universe and Earth’s place in the cosmos\\\\\\\"\\\", \\\"laureates\\\": [{\\\"id\\\": \\\"973\\\", \\\"firstname\\\": \\\"James\\\", \\\"surname\\\": \\\"Peebles\\\", \\\"motivation\\\": \\\"\\\\\\\"for theoretical discoveries in physical cosmology\\\\\\\"\\\", \\\"share\\\": \\\"2\\\"}, {\\\"id\\\": \\\"974\\\", \\\"firstname\\\": \\\"Michel\\\", \\\"surname\\\": \\\"Mayor\\\", \\\"motivation\\\": \\\"\\\\\\\"for the discovery of an exoplanet orbiting a solar-type star\\\\\\\"\\\", \\\"share\\\": \\\"4\\\"}, {\\\"id\\\": \\\"975\\\", \\\"firstname\\\": \\\"Didier\\\", \\\"surname\\\": \\\"Queloz\\\", \\\"motivation\\\": \\\"\\\\\\\"for the discovery of an exoplanet orbiting a solar-type star\\\\\\\"\\\", \\\"share\\\": \\\"4\\\"}]}, {\\\"year\\\": \\\"1901\\\", \\\"category\\\": \\\"physics\\\", \\\"laureates\\\": [{\\\"id\\\": \\\"1\\\", \\\"firstname\\\": \\\"Wilhelm Conrad\\\", \\\"surname\\\": \\\"Röntgen\\\", \\\"motivation\\\": \\\"\\\\\\\"in recognition of the extraordinary services he has rendered by the discovery of the remarkable rays subsequently named after him\\\\\\\"\\\", \\\"share\\\": \\\"1\\\"}]}, {\\\"year\\\": \\\"1901\\\", \\\"category\\\": \\\"medicine\\\", \\\"laureates\\\": [{\\\"id\\\": \\\"293\\\", \\\"firstname\\\": \\\"Emil\\\", \\\"surname\\\": \\\"von Behring\\\", \\\"motivation\\\": \\\"\\\\\\\"for his work on serum therapy, especially its application against diphtheria, by which he has opened a new road in the domain of medical science and thereby placed in the hands of the physician a victorious weapon against illness and deaths\\\\\\\"\\\", \\\"share\\\": \\\"1\\\"}]}], \\\"summary\\\": \\\"test\\\"}}\"\n",
    "test_save_schema(ENTITY_NAME, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_save_schema(entity_name, file_path):\n",
    "    data = ''\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = file.read()\n",
    "            print(data)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read JSON file: {e}\")\n",
    "        return\n",
    "    response = save_entity_schema(\n",
    "        entity_name=entity_name, version=MODEL_VERSION, data=data\n",
    "    )\n",
    "    logger.info(response)\n",
    "    assert (\n",
    "        response.status_code == 200\n",
    "    ), f\"Expected 200, got {response.status_code}\"\n",
    "\n",
    "file_path_base = f\"{WORK_DIR}/config-generation/prizes_schema.json\"\n",
    "test_save_schema(ENTITY_NAME, file_path_base)\n",
    "\n",
    "file_path_agg = f\"{WORK_DIR}/config-generation/prizes_agg_schema.json\"\n",
    "test_save_schema(AGG_ENTITY_NAME, file_path_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lock_entity_schema(entity_name, version, data):\n",
    "    path = f\"treeNode/model/{entity_name}/{version}/lock\"\n",
    "    response = send_put_request(path=path, data=data, timeout=None)\n",
    "    logger.info(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lock_schema(entity_name):\n",
    "    employees_response = lock_entity_schema(entity_name=entity_name, version=MODEL_VERSION, data=None)\n",
    "    logger.info(employees_response)\n",
    "    assert (\n",
    "        employees_response.status_code == 200\n",
    "    ), f\"Expected 200, got {employees_response.status_code}\"\n",
    "\n",
    "\n",
    "test_lock_schema(ENTITY_NAME)\n",
    "test_lock_schema(AGG_ENTITY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def save_new_entity(entity_name, version, data):\n",
    "    path = f\"entity/new/JSON/TREE/{entity_name}/{version}\"\n",
    "    response = send_post_request(path=path, data=data)\n",
    "    # Save entities ids for later use in the tests\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        print(response_json)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def test_save_new_entity(entity_name, data):\n",
    "    employees_response = save_new_entity(\n",
    "        entity_name=entity_name, version=MODEL_VERSION, data=data\n",
    "    )\n",
    "    #logger.info(employees_response.json())\n",
    "    assert (\n",
    "        employees_response.status_code == 200\n",
    "    ), f\"Expected 200, got {employees_response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def test_save_new_entity_from_file(entity_name, file_path):\n",
    "    \n",
    "    data = ''\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = file.read()\n",
    "            print(data)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read JSON file: {e}\")\n",
    "        return\n",
    "    employees_response = save_new_entity(\n",
    "        entity_name=entity_name, version=MODEL_VERSION, data=data\n",
    "    )\n",
    "    #logger.info(employees_response.json())\n",
    "    assert (\n",
    "        employees_response.status_code == 200\n",
    "    ), f\"Expected 200, got {employees_response.status_code}\"\n",
    "\n",
    "#file_path_base = f\"{WORK_DIR}/config-generation/prizes_entities.json\"\n",
    "#test_save_new_entity(ENTITY_NAME, file_path_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "def get_entity_current_state(entityId):\n",
    "    \n",
    "    path = f\"platform-api/entity-info/fetch/lazy?entityClass={ENTITY_CLASS_NAME}&entityId={entityId}&columnPath=state\"\n",
    "    response = send_get_request(path=path)\n",
    "    logger.info(response)\n",
    "    return response\n",
    "get_entity_current_state('a057d654-1e01-11b2-89dd-16bcbffd08fd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(model, version):\n",
    "    \n",
    "    path = f\"entity/TREE/{model}/{version}\"\n",
    "    response = send_get_request(path=path)\n",
    "    print(response.json())\n",
    "    return response\n",
    "get_entities(ENTITY_NAME, MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_transition(entityId, transitionName):\n",
    "    \n",
    "    path = f\"platform-api/entity/transition?entityId={entityId}&entityClass={ENTITY_CLASS_NAME}&transitionName={transitionName}\"\n",
    "    timeout = (30, 30)\n",
    "    response = send_put_request(path=path, data=None, timeout = timeout)\n",
    "    logger.info(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install gRPC and tools\n",
    "!pip install grpcio grpcio-tools\n",
    "\n",
    "# Step 2: Compile proto files\n",
    "!python -m grpc_tools.protoc -I. --python_out=. --pyi_out=. --grpc_python_out=. cyoda-cloud-api.proto\n",
    "\n",
    "!python -m grpc_tools.protoc -I. --python_out=. --pyi_out=. --grpc_python_out=. cloudevents.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from enum import Enum\n",
    "from typing import Any, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CloudEventType(str, Enum):\n",
    "    BASE_EVENT = \"BaseEvent\"\n",
    "    CALCULATION_MEMBER_JOIN_EVENT = \"CalculationMemberJoinEvent\"\n",
    "    CALCULATION_MEMBER_GREET_EVENT = \"CalculationMemberGreetEvent\"\n",
    "    ENTITY_PROCESSOR_CALCULATION_REQUEST = \"EntityProcessorCalculationRequest\"\n",
    "    ENTITY_PROCESSOR_CALCULATION_RESPONSE = \"EntityProcessorCalculationResponse\"\n",
    "\n",
    "class DataPayload(BaseModel):\n",
    "    type: str\n",
    "    data: Optional[Any] = None\n",
    "    \n",
    "    \n",
    "class ErrorCode(BaseModel):\n",
    "    code: str\n",
    "    message: str\n",
    "\n",
    "\n",
    "class BaseEvent(BaseModel):\n",
    "    owner: str\n",
    "    success: Optional[bool] = True\n",
    "    error: Optional[ErrorCode] = None\n",
    "    \n",
    "    \n",
    "class CalculationMemberGreetEvent(BaseEvent):\n",
    "    memberId: str\n",
    "    \n",
    "    \n",
    "class CalculationMemberJoinEvent(BaseEvent):\n",
    "    tags: Optional[List[str]] = None\n",
    "    \n",
    "    \n",
    "class EntityProcessorCalculationRequest(BaseEvent):\n",
    "    requestId: str\n",
    "    entityId: str\n",
    "    processorId: str\n",
    "    processorName: str\n",
    "    payload: DataPayload\n",
    "    \n",
    "    \n",
    "class EntityProcessorCalculationResponse(BaseEvent):\n",
    "    requestId: str\n",
    "    entityId: str\n",
    "    payload: DataPayload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "WORK_DIR = os.environ[\"WORK_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pysqlite3-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "__import__(\"pysqlite3\")\n",
    "sys.modules[\"sqlite3\"] = sys.modules[\"pysqlite3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import GitLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    max_tokens=8000,\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "loader = GitLoader(\n",
    "    repo_path=WORK_DIR,\n",
    "    branch=\"cyoda-ai-configurations-3.0.x\",\n",
    "    file_filter=lambda file_path: file_path.startswith(f\"{WORK_DIR}/data/code/\"),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents loaded: {len(docs)}\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(\n",
    "            documents=splits, embedding=OpenAIEmbeddings()\n",
    "        )\n",
    "retriever = vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 10}\n",
    "        )\n",
    "\n",
    "count = vectorstore._collection.count()\n",
    "print(count)\n",
    "\n",
    "\n",
    "res = vectorstore.similarity_search(\"Get FOREIGN TRAVEL FOR LEEDS CITY COUNCIL\")\n",
    "print(res)\n",
    "\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "qa_system_prompt = \"\"\"You are a data analyst assistant. Summarize and aggregata data you receive. Provide the short summary. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "chat_history = {}\n",
    "\n",
    "# Function to add a message to the chat history\n",
    "def add_to_chat_history(id, question, message):\n",
    "    if id in chat_history:\n",
    "        chat_history[id].extend([HumanMessage(content=question), message])\n",
    "    else:\n",
    "        chat_history[id] = [HumanMessage(content=question), message]\n",
    "\n",
    "# Function to clear chat history\n",
    "def clear_chat_history(id):\n",
    "    if id in chat_history:\n",
    "        del chat_history[id]\n",
    "\n",
    "def ask_question(id, question):\n",
    "    ai_msg = rag_chain.invoke(\n",
    "        {\"input\": question, \"chat_history\": chat_history.get(id, [])}\n",
    "    )\n",
    "    add_to_chat_history(id, question, ai_msg[\"answer\"])\n",
    "    return ai_msg[\"answer\"]\n",
    "\n",
    "import uuid\n",
    "\n",
    "# Generate a unique ID for the chat session\n",
    "id = uuid.uuid1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandasai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "\n",
    "llm = OpenAI(api_token=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def aggregate_prizes(prizes) -> str:\n",
    "    records = []\n",
    "    for prize in prizes:\n",
    "        year = prize['year']\n",
    "        category = prize['category']\n",
    "        for laureate in prize['laureates']:\n",
    "            record = {\n",
    "                \"year\": year,\n",
    "                \"category\": category,\n",
    "                \"id\": laureate.get('id', ''),\n",
    "                \"firstname\": laureate.get('firstname', ''),\n",
    "                \"surname\": laureate.get('surname', ''),\n",
    "                \"motivation\": laureate.get('motivation', ''),\n",
    "                \"share\": int(laureate.get('share', 0))\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    sdf = SmartDataframe(df, config={\"llm\": llm})\n",
    "\n",
    "    response = sdf.chat('What are top catagories? Make a report')\n",
    "    print(response)\n",
    "\n",
    "    # Total number of prizes\n",
    "    total_prizes = len(prizes)\n",
    "\n",
    "    # Total number of laureates\n",
    "    total_laureates = df['id'].nunique()\n",
    "\n",
    "    # Number of prizes per year\n",
    "    prizes_per_year = df.groupby('year')['category'].nunique().to_dict()\n",
    "\n",
    "    # Number of prizes per category\n",
    "    prizes_per_category = df.groupby('category')['year'].nunique().to_dict()\n",
    "\n",
    "    # Number of laureates per year\n",
    "    laureates_per_year = df.groupby('year')['id'].nunique().to_dict()\n",
    "\n",
    "    # Number of laureates per category\n",
    "    laureates_per_category = df.groupby('category')['id'].nunique().to_dict()\n",
    "\n",
    "    # Average share per laureate\n",
    "    average_share_per_laureate = int(df['share'].mean())\n",
    "\n",
    "    # Total share per prize\n",
    "    total_share_per_prize = df.groupby(['year', 'category'])['share'].sum().to_dict()\n",
    "\n",
    "    # Construct the JSON object\n",
    "    metrics = [\n",
    "        {\n",
    "            \"metric\": \"Total number of prizes\",\n",
    "            \"value\": total_prizes\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Total number of laureates\",\n",
    "            \"value\": total_laureates\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Number of prizes per year\",\n",
    "            \"value\": prizes_per_year\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Number of prizes per category\",\n",
    "            \"value\": prizes_per_category\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Number of laureates per year\",\n",
    "            \"value\": laureates_per_year\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Number of laureates per category\",\n",
    "            \"value\": laureates_per_category\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Average share per laureate\",\n",
    "            \"value\": average_share_per_laureate\n",
    "        },\n",
    "        {\n",
    "            \"metric\": \"Total share per prize\",\n",
    "            \"value\": total_share_per_prize\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    result = {\n",
    "        \"related_entity_name\": \"prizes\",\n",
    "        \"related_entity_model_version\": \"10\",\n",
    "        \"related_entity_id\": \"462bad7a-43bf-11b2-9b19-621ba7a93ed7\",\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "    # Function to convert the tuple keys in the nested dictionary to string keys\n",
    "    def convert_keys_to_strings(d):\n",
    "        if isinstance(d, dict):\n",
    "            return {str(k): convert_keys_to_strings(v) for k, v in d.items()}\n",
    "        elif isinstance(d, list):\n",
    "            return [convert_keys_to_strings(i) for i in d]\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "    # Convert the tuple keys in the nested dictionary\n",
    "    converted_data = convert_keys_to_strings(result)\n",
    "\n",
    "    # Convert the modified object to JSON\n",
    "    json_data = json.dumps(converted_data, indent=2)\n",
    "\n",
    "    print(json_data)\n",
    "    return json_data\n",
    "\n",
    "file_path = f\"{WORK_DIR}/config-generation/prizes_entities.json\"\n",
    "data = ''\n",
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        print(data)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to read JSON file: {e}\")\n",
    "\n",
    "# Flatten the data\n",
    "prizes = data['data']['prizes']\n",
    "prizes_agg_result = aggregate_prizes(prizes);\n",
    "print(prizes_agg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import json\n",
    "import asyncio\n",
    "import cloudevents_pb2 as cloudevents_pb2\n",
    "import cloudevents_pb2_grpc as cloudevents_pb2_grpc\n",
    "import cyoda_cloud_api_pb2 as cyoda_cloud_api_pb2\n",
    "import cyoda_cloud_api_pb2_grpc as cyoda_cloud_api_pb2_grpc\n",
    "\n",
    "def save_prizes_agg_entity(data):\n",
    "    prizes = data['payload']['data']['data'].get('prizes', [])\n",
    "    prizes_agg_result = aggregate_prizes(prizes)\n",
    "    test_save_new_entity(AGG_ENTITY_NAME, prizes_agg_result)\n",
    "\n",
    "def ai_post_process(data) -> str:\n",
    "    result = ask_question(id, data)\n",
    "    return result\n",
    "\n",
    "def add_summary_to_prizes(data):\n",
    "    \"\"\"\n",
    "    Adds a 'summary' attribute to each prize in the JSON data.\n",
    "    \"\"\"\n",
    "    prizes = data['payload']['data']['data'].get('prizes', [])\n",
    "    for prize in prizes:\n",
    "        summary = ai_post_process(json.dumps(prize))\n",
    "        prize['summary'] = ''+ summary\n",
    "    return data\n",
    "\n",
    "def create_cloud_event(event_id, source, event_type, data) -> cloudevents_pb2.CloudEvent:\n",
    "    return cloudevents_pb2.CloudEvent(\n",
    "        id=event_id,\n",
    "        source=source,\n",
    "        spec_version=\"1.0\",\n",
    "        type=event_type,\n",
    "        text_data=json.dumps(data)\n",
    "    )\n",
    "\n",
    "def send_notification(data) -> cloudevents_pb2.CloudEvent:\n",
    "    print(\"SENDING EVENT!\")\n",
    "    return create_cloud_event(\n",
    "        event_id=\"8f54729e-994d-4035-8bf9-e7cfe847e2cd\",\n",
    "        source=\"SimpleSample\",\n",
    "        event_type=\"EntityProcessorCalculationResponse\",\n",
    "        data={\n",
    "            \"requestId\": data['requestId'],\n",
    "            \"entityId\": data['entityId'],\n",
    "            \"owner\": \"PLAY\",\n",
    "            \"payload\": data['payload'],\n",
    "            \"success\": True\n",
    "        }\n",
    "    )\n",
    "    \n",
    "\n",
    "async def event_producer(queue):\n",
    "    cloud_event = create_cloud_event(\n",
    "        event_id=\"9ba80b3e-e856-4bdb-984b-7523a458101b\",\n",
    "        source=\"SimpleSample\",\n",
    "        event_type=\"CalculationMemberJoinEvent\",\n",
    "        data={\"owner\": \"PLAY\", \"tags\": [\"prizes\"]}\n",
    "    )\n",
    "\n",
    "    await queue.put(cloud_event)\n",
    "    await asyncio.sleep(10)\n",
    "    test_save_new_entity_from_file(ENTITY_NAME, f\"{WORK_DIR}/config-generation/prizes_entities.json\")\n",
    "    await asyncio.sleep(35)\n",
    "    print(\"Closing the connection\")\n",
    "    await queue.put(None)\n",
    "    await asyncio.sleep(10)\n",
    "    raise asyncio.TimeoutError(\"Operation timed out!\")\n",
    "\n",
    "async def event_consumer(queue):\n",
    "    async with grpc.aio.secure_channel(GRPC_ADDRESS, grpc.ssl_channel_credentials()) as channel:\n",
    "        stub = cyoda_cloud_api_pb2_grpc.CloudEventsServiceStub(channel)\n",
    "\n",
    "        async def generate_events():\n",
    "            while True:\n",
    "                event = await queue.get()\n",
    "                if event is None:\n",
    "                    break\n",
    "                yield event\n",
    "                queue.task_done()\n",
    "\n",
    "        async for response in stub.startStreaming(generate_events()):\n",
    "            print(\"Received event: \", response)\n",
    "            data = json.loads(response.text_data)\n",
    "            if 'processorName' in data and data['processorName'] == 'ai_transform_entity':\n",
    "                #add_summary_to_prizes(data);\n",
    "                save_prizes_agg_entity(data);\n",
    "                cloud_event = send_notification(data)\n",
    "                await queue.put(cloud_event)\n",
    "\n",
    "async def main():\n",
    "    queue = asyncio.Queue()\n",
    "    producer = event_producer(queue)\n",
    "    consumer = event_consumer(queue)\n",
    "\n",
    "    await asyncio.gather(producer, consumer)\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_entities(ENTITY_NAME, MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_entities(AGG_ENTITY_NAME, MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = delete_entity_data(ENTITY_NAME, MODEL_VERSION)\n",
    "logger.info(response)\n",
    "response = delete_entity_data(AGG_ENTITY_NAME, MODEL_VERSION)\n",
    "logger.info(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

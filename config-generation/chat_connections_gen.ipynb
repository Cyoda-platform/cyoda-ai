{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Cyoda configurations Q&A with RAG Langchain\n",
    "\n",
    "Welcome to this Jupyter notebook! This notebook serves as your guide to developing an AI-powered Question & Answer system using the Langchain library. This system utilizes the Retrieval-Augmented Generation (RAG) model that leverages OpenAI's GPT-3 model to provide intelligent and context-aware responses.\n",
    "\n",
    "The primary purpose of this notebook is to generate Cyoda related code. It does so by interacting with the data set available in the official Cyoda repository. \n",
    "\n",
    "## What will we cover?\n",
    "\n",
    "In this notebook, we will go through the following steps:\n",
    "\n",
    "1. **Setting up the environment**: We will install necessary libraries and load environment variables.\n",
    "\n",
    "2. **Initializing the AI model**: We will initialize the ChatOpenAI model with the appropriate parameters.\n",
    "\n",
    "3. **Loading instructions and entities**: We will load instructions and entities from the official repository using the GitLoader.\n",
    "\n",
    "4. **Splitting documents and creating a vectorstore**: We will split the loaded documents into chunks and create a vectorstore using the Chroma library.\n",
    "\n",
    "5. **Defining prompts for contextualizing and answering questions**: We will define prompts that the AI model will use to contextualize and answer questions.\n",
    "\n",
    "6. **Creating a retrieval chain**: We will create a retrieval chain that combines the history-aware retriever and the question-answer chain.\n",
    "\n",
    "7. **Running the chatbot**: Finally, we will run the chatbot and see it in action!\n",
    "\n",
    "## Let's get started!\n",
    "\n",
    "Please follow along with the code cells and comments to understand each step of the process. If you have any questions or run into any issues, feel free to ask for help. Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "WORK_DIR = os.environ[\"WORK_DIR\"]\n",
    "API_KEY = os.environ[\"CYODA_API_KEY\"]\n",
    "API_SECRET = os.environ[\"CYODA_API_SECRET\"]\n",
    "API_URL = os.environ[\"CYODA_API_URL\"]+\"/api\"\n",
    "GRPC_ADDRESS = os.environ[\"GRPC_ADDRESS\"]\n",
    "WORK_DIR = os.environ[\"WORK_DIR\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "WORK_DIR = os.environ[\"WORK_DIR\"]\n",
    "TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_CLASS_NAME = \"com.cyoda.tdb.model.treenode.TreeNodeEntity\"\n",
    "ENTITY_NAME=\"prizes\"\n",
    "AGG_ENTITY_NAME=ENTITY_NAME+\"_agg\"\n",
    "MODEL_VERSION=\"1001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "##for google colab (optional)\n",
    "# This cell is optional and can be skipped\n",
    "from google.colab import userdata\n",
    "API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "WORK_DIR = userdata.get('WORK_DIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle unsupported version of sqlite3 (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pysqlite3-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "__import__(\"pysqlite3\")\n",
    "sys.modules[\"sqlite3\"] = sys.modules[\"pysqlite3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import GitLoader, DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.85,\n",
    "    max_tokens=4000,\n",
    "    model=\"gpt-4o\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load instructions and entities from the official cyoda repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "loader = GitLoader(\n",
    "    repo_path=WORK_DIR,\n",
    "    branch=\"cyoda-ai-configurations-3.0.x\",\n",
    "    file_filter=lambda file_path: file_path.startswith(f\"{WORK_DIR}/data/rag/v1/connections/templates\"),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\n",
    "    f\"{WORK_DIR}/data/v1/connections/templates\", loader_cls=TextLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents loaded: {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents and create vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(\n",
    "            documents=splits, embedding=OpenAIEmbeddings()\n",
    "        )\n",
    "retriever = vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 10}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = vectorstore._collection.count()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = vectorstore.similarity_search(\"Get FOREIGN TRAVEL FOR LEEDS CITY COUNCIL\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define prompts for contextualizing question and answering question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are a connection generation assistant. You are provided with connection_dto_template.json with bean com.cyoda.plugins.datasource.dtos.DataSourceConfigsContainerDto template. \\\n",
    "In the template there are blanks <> which you need to fill in after analysing user input. Return the rresulting json without any comments.\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create retrieval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize chat history and relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a message to the chat history\n",
    "def add_to_chat_history(id, question, message):\n",
    "    if id in chat_history:\n",
    "        chat_history[id].extend([HumanMessage(content=question), message])\n",
    "    else:\n",
    "        chat_history[id] = [HumanMessage(content=question), message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear chat history\n",
    "def clear_chat_history(id):\n",
    "    if id in chat_history:\n",
    "        del chat_history[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(id, question):\n",
    "    ai_msg = rag_chain.invoke(\n",
    "        {\"input\": question, \"chat_history\": chat_history.get(id, [])}\n",
    "    )\n",
    "    add_to_chat_history(id, question, ai_msg[\"answer\"])\n",
    "    return ai_msg[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Generate a unique ID for the chat session\n",
    "id = uuid.uuid1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rewrite CyodaCalculationMemberClient to java. Produce ready to use code. Leave spring boot\n",
    "question = \"Create a connection for GET https://raw.githubusercontent.com/Cyoda-platform/cyoda-ai/cyoda-ai-configurations-3.0.x/config-generation/prizes_entities.json\"\n",
    "result = ask_question(id, question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with the Cyoda API\n",
    "import requests\n",
    "import json\n",
    "\n",
    "api_url = API_URL + \"/auth/login\"\n",
    "headers = {\"Content-Type\": \"application/json\", \"X-Requested-With\": \"XMLHttpRequest\"}\n",
    "auth_data = {\"username\": API_KEY, \"password\": API_SECRET}\n",
    "logger.info(api_url)\n",
    "response = requests.post(api_url, headers=headers, data=json.dumps(auth_data))\n",
    "if response.status_code == 200:\n",
    "    logger.info(\"Authentication successful!\")\n",
    "    TOKEN = response.json().get(\"token\")\n",
    "else:\n",
    "    logger.info(\"Authentication failed. Please check your API credentials.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_post_request(path, data):\n",
    "    url = f\"{API_URL}/{path}\"\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {TOKEN}\"}\n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data):\n",
    "    path = f\"data-source-config/import-cobi-config?cleanBeforeImport=false&doPostProcess=false\"\n",
    "    response = send_post_request(path=path, data=data)\n",
    "    logger.info(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def test_save_data(file_path):\n",
    "    data = ''\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = file.read()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read JSON file: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        data = json.loads(data)  # Parse the JSON string into a dictionary\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Failed to decode JSON: {e}\")\n",
    "        return\n",
    "\n",
    "    # Ensure `result` is correctly formatted as a JSON-compatible object\n",
    "    \n",
    "\n",
    "    try:\n",
    "        result_json = json.loads(result)\n",
    "        data['dataSources'] = result_json['dataSources']\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Failed to decode result as JSON: {e}\")\n",
    "        return\n",
    "\n",
    "    # Convert the modified dictionary back to a JSON string\n",
    "    data = json.dumps(data, indent=4)\n",
    "    print(data)\n",
    "\n",
    "    response = save_data(data=data)\n",
    "    logger.info(response)\n",
    "    assert (\n",
    "        response.status_code == 200\n",
    "    ), f\"Expected 200, got {response.status_code}\"\n",
    "\n",
    "file_path_base = f\"{WORK_DIR}/data/v1/connections/templates/connection_dto_template.json\"\n",
    "test_save_data(file_path_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear chat history if necessary\n",
    "clear_chat_history(id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
